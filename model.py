# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JMPM_hNsNzX7_69h7SEa7kRwI0qi_keM
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelEncoder
#from sklearn.externals import joblib
import joblib
import pandas
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
import itertools
import matplotlib.style as style
from mpl_toolkits.mplot3d import Axes3D
import os # accessing directory structure
import plotly
import plotly.express as px
# graphs to be inline
# %matplotlib inline
import re
# Tutorial about Python regular expressions: https://pymotw.com/2/re/
from sklearn.preprocessing import OneHotEncoder
import pickle
from tqdm import tqdm
import os
from collections import Counter
from sklearn.preprocessing import StandardScaler

import re
import time
from nltk.corpus import stopwords
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import normalize
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics._classification import accuracy_score, log_loss
from sklearn.linear_model import SGDClassifier
from scipy.sparse import hstack
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold 
from collections import Counter, defaultdict
from sklearn.calibration import CalibratedClassifierCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
import math
from sklearn.metrics import normalized_mutual_info_score
warnings.filterwarnings("ignore")
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.manifold import TSNE
from numpy import loadtxt
from xgboost import XGBClassifier
from scipy.stats import randint as sp_randint
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint
from sklearn.datasets import make_classification
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import roc_curve, auc
from matplotlib.legend_handler import HandlerLine2D
from scipy.stats import uniform
import random

def Nullvalue(loan_process_df):
  Categorical_feature=[feature for feature in loan_process_df.columns if loan_process_df[feature].dtypes == 'O' and feature not in ['TARGET']]
  for i in Categorical_feature:
    loan_process_df[i].fillna(loan_process_df[i].mode()[0], inplace=True)  

  continuous_feature=[feature for feature in loan_process_df.columns if loan_process_df[feature].dtypes != 'O' and feature not in ['TARGET']]
  for j in continuous_feature:
    loan_process_df[j].fillna(loan_process_df[j].median(),inplace = True)
  return loan_process_df

loan_process_df=pd.read_csv('loan_process_df_before_StandardScaler_onehot.csv')

loan_process_df.drop(labels='SK_ID_CURR',axis=1,inplace=True)

loan_process_df= Nullvalue(loan_process_df)

#Categorical feature encoding
Categorical_feature=[feature for feature in loan_process_df if loan_process_df[feature].dtypes == 'O'and feature not in ['TARGET']]
ohehot = OneHotEncoder(sparse=False,handle_unknown='ignore')
ohehot.fit(loan_process_df[Categorical_feature])
joblib.dump(ohehot, 'ohehot.pkl')
data_cat=ohehot.transform(loan_process_df[Categorical_feature])
cat_cols_ohe = list(ohehot.get_feature_names(input_features=Categorical_feature))
data_cat_final = pd.DataFrame(data_cat, columns = cat_cols_ohe)

#Numerical feature encoding
continuous_feature=[feature for feature in loan_process_df if loan_process_df[feature].dtypes != 'O' and feature not in ['TARGET']]
scaler=StandardScaler()
scaler.fit(loan_process_df[continuous_feature])
joblib.dump(scaler, 'scaler.pkl')
data_Num=scaler.transform(loan_process_df[continuous_feature])
data_Num_final=pd.DataFrame(data_Num, columns=continuous_feature)
data = pd.concat([loan_process_df[['TARGET']].reset_index(drop=True),data_Num_final],axis=1)

# Final complete data
data_final = pd.concat([data_cat_final,data], axis = 1)
print(data_final.shape)

y = data_final['TARGET'].values
X = data_final.drop(['TARGET'], axis=1)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)
X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.33, stratify=y_train)

y_train.shape

Train_mer=np.concatenate((np.array(X_train),np.array(y_train).reshape(504023,1)),axis=1)

from sklearn.utils import resample

majority =Train_mer[Train_mer[:,-1]==0]
minority =Train_mer[Train_mer[:,-1]==1]

downsample =resample(majority,replace=False,n_samples=minority.shape[0])
X_train_new =np.concatenate([downsample,minority])

y_train_new =X_train_new[:,-1]
X_train_new =X_train_new[:,:-1]

X_train_new.shape

# plot feature importance manually
neigh = RandomForestClassifier(bootstrap=True, class_weight="balanced_subsample", criterion='gini',random_state=25,n_jobs=-1,max_depth=7,n_estimators=100)
neigh.fit(X_train_new,y_train_new)
joblib.dump(neigh, 'model.pkl')

def predict(df):

    loan_process_df= Nullvalue(df)

    Categorical_feature=[feature for feature in loan_process_df if loan_process_df[feature].dtypes == 'O'and feature not in ['TARGET']]
    ohehot= joblib.load('ohehot.pkl')
    data_cat=ohehot.transform(loan_process_df[Categorical_feature])
    cat_cols_ohe = list(ohehot.get_feature_names(input_features=Categorical_feature))
    data_cat_final = pd.DataFrame(data_cat, columns = cat_cols_ohe)

    continuous_feature=[feature for feature in loan_process_df if loan_process_df[feature].dtypes != 'O' and feature not in ['TARGET']]
    scaler= joblib.load('scaler.pkl')
    data_Num=scaler.transform(loan_process_df[continuous_feature])
    data_Num_final=pd.DataFrame(data_Num, columns=continuous_feature)

    # Final complete data
    data_final = pd.concat([data_cat_final,data_Num_final], axis = 1)
    print(data_final.shape)
    clf = joblib.load('model.pkl')
    pred = clf.predict(data_final)

    print(pred[0])
    if pred[0]==0:
        prediction = "Non-defaulter"
    else:
        prediction = "Defaulter"
    return prediction

# few reviews from
# https://www.amazon.in/Nescaf%C3%A9-Classic-Coffee-Glass-Jar/dp/B01GO164O4
#pred_df=pd.read_csv("/content/drive/MyDrive/Loan Defaulter/sample.csv")
#pre=predict(pred_df)
#print(pre)